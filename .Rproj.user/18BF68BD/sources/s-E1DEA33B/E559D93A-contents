---
title: "Práctica 2: Deep Learning para clasificación"
author: "Francisco José González García"
output:
  pdf_document:
      toc: yes
      toc_depth: 2
  html_document:
      code_folding: "show"
      toc: true
      toc_depth: 2
      toc_float: true
      df_print: paged
---

\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
library(reticulate)
use_condaenv('r-tensorflow')
library(keras)

#### WORKARROUND para que TF funcione en GPU, comentar las lineas si se actualiza
# y se resuelve el bug https://github.com/tensorflow/tensorflow/issues/43174
library(tensorflow)
physical_devices <- tf$config$list_physical_devices('GPU')
tf$config$experimental$set_memory_growth(physical_devices[[1]], TRUE)
####

```

El conjunto de datos Fakeeddit contiene más de un millón de publicaciones de Reddit que contienen algún tipo de desinformación. El problema de clasificación con Fakeddit consiste en predecir si una publicación es una "noticia falsa". Existen varias versiones del problema según las categorías de "falsedad", desde clasificación binaria a clasificación con seis clases.

# Carga de datos

Directorios:

```{r}
dataset_dir           <- './datasets/medium10000_twoClasses/'

train_images_dir      <- paste0(dataset_dir, 'train')
val_images_dir        <- paste0(dataset_dir, 'val')
test_images_dir       <- paste0(dataset_dir, 'test')
```

Generadores:

```{r}
# https://tensorflow.rstudio.com/keras/reference/image_data_generator.html 
train_images_generator <- image_data_generator(rescale = 1/255)
val_images_generator   <- image_data_generator(rescale = 1/255)
test_images_generator  <- image_data_generator(rescale = 1/255)
```

Flujos:

```{r}
# https://tensorflow.rstudio.com/keras/reference/flow_images_from_directory.html
# https://forums.fast.ai/t/split-data-using-fit-generator/4380/4
train_generator_flow <- flow_images_from_directory(
  directory = train_images_dir,
  generator = train_images_generator,
  class_mode = 'categorical',
  batch_size = 5,
  target_size = c(64, 64)         # (w x h) --> (64 x 64)
)

validation_generator_flow <- flow_images_from_directory(
  directory = val_images_dir,
  generator = val_images_generator,
  class_mode = 'categorical',
  batch_size = 5,
  target_size = c(64, 64)         # (w x h) --> (64 x 64)
)

test_generator_flow <- flow_images_from_directory(
  directory = test_images_dir,
  generator = test_images_generator,
  class_mode = 'categorical',
  batch_size = 5,
  target_size = c(64, 64)         # (w x h) --> (64 x 64)
)
```

Metadatos:

```{r}
metadata_train <- read_tsv(paste0(train_images_dir, "/multimodal_train.tsv"))
metadata_train <- metadata_train %>%
  mutate(created_at = as.POSIXct(created_utc, origin="1970-01-01")) %>%
  mutate(class = ifelse(`2_way_label` == 0, 'Disinformation', 'Other')) %>% 
  select(-all_of(c('created_utc', '6_way_label', '3_way_label', '2_way_label' )))
```

# Análisis exploratorio

Visión general del conjunto de datos:

```{r resumen}
summary(metadata_train)
```

Estado del conjunto de datos:

```{r status}
library(funModeling)
df_status(metadata_train)
```

## Analizar clases

Vamos a analizar cuántos valores tenemos de cada clase:

```{r tabla}
table(metadata_train$class)
```

Y crear un histograma:

```{r clases, warning=FALSE}
ggplot(metadata_train) +
geom_histogram(aes(x = class, fill = as.factor(class)), stat = "count") +
labs(x = "", y = "") 
```

## Analizando en que subreddit hay mayor desinformación

```{r}
plotdata <- metadata_train %>%
  filter(class == "Disinformation") %>%
  count(subreddit) %>%
  slice_max(n = 15, order_by = n, with_ties = FALSE)
  
ggplot(plotdata) +
  geom_bar(aes(x = subreddit, y = n), stat = 'identity') +
  coord_flip()
```

## Evolución

Evolución temporal (frecuencia acumulada):

```{r}
library(scales)
ggplot(metadata_train, aes(x = created_at)) +
  geom_histogram(aes(fill = class))
```

Nos quedamos con las columnas relevantes e inputamos los valores perdidos:

```{r results='hide'}
library(mice)
data_binary_factors <- metadata_train %>%
  select(-one_of("author", "clean_title", "id", "image_url", "linked_submission_id", "title", 'domain')) %>%
  mutate_if(is.character, as.factor)
imputation <- mice(data_binary_factors, defaultMethod = c('mean', 'logreg', 'polyreg', 'polr'))
train <- complete(imputation) %>% na.omit()
```

# Clasificación

## Clasificación binaria usando imágenes

Como primera aproximación para resolver el problema de clasificación binaria entrenaremos un modelo que será entrenado con el conjunto de imágenes de prueba. El primer modelo utilizado será una red convolucional a la que le aplicaremos diferentes técnicas de mejora de aprendizaje. En concreto aplicaremos técnicas de:

-   Normalización: aplicaremos capas `layer_batch_normalization` a continuación de las capas convolucionales.
-   Early Stopping: se realizará un guardado periódico del modelo para ir supervisando el error de validación y terminar la ejecución cuando ese error aumente.
-   Dropout: aplicaremos capas `dropout` a las capas densas para prevenir el sobreaprendizaje.

### Creación del modelo

```{r warning=TRUE}
model <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32,  kernel_size = c(3, 3), activation = "relu", input_shape = c(64, 64, 3)) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 64,  kernel_size = c(3, 3), activation = "relu") %>% layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_flatten() %>%
  layer_dense(units = 512, activation = "relu") %>%
  layer_dense(units = 2, activation = "softmax")
```

Compilar modelo:

```{r}
model %>% compile(
  loss = 'categorical_crossentropy',
  optimizer = optimizer_rmsprop(),
  metrics = c('accuracy')
)
```

### Entrenamiento

#### Inciso. Eliminando imágenes corruptas

Cuando me disponía a entrenar la red, keras me lanzaba el siguiente error: `UnidentifiedImageError: cannot identify image file`, así que me imaginé que había alguna imagen que no estaba funcionando correctamente. Para solucionarlo he creado un pequeño script en python que recorre todas las imágenes del dataset y detecta si hay algún error con ellas, el script en cuestión es `check_images.py`. Tras lanzar el script se detectó que las siguientes imágenes estaban corruptas: `['datasets/medium10000_twoClasses/val/0/d0moj4t.jpg', 'datasets/medium10000_twoClasses/train/0/cakwaac.jpg', 'datasets/medium10000_twoClasses/train/0/c6znmkl.jpg', 'datasets/medium10000_twoClasses/train/0/d14o3im.jpg', 'datasets/medium10000_twoClasses/train/0/c82s1pm.jpg', 'datasets/medium10000_twoClasses/train/0/cqgihgw.jpg', 'datasets/medium10000_twoClasses/train/0/c6o24rp.jpg', 'datasets/medium10000_twoClasses/train/0/cfiq37y.jpg', 'datasets/medium10000_twoClasses/train/0/c50lt7l.jpg']`

EDIT: Posteriormente he visto que ya se había dado este problema y que había una solución propuesta en el GitHub de la asignatura, de todas formas dejo el script que he usado yo, ya que está hecho.

Ahora si, vamos a entrenar la red.

```{r}
history <- model %>% 
  fit_generator(
    generator = train_generator_flow, 
    validation_data = validation_generator_flow,
    steps_per_epoch = 10,
    epochs = 5
  )
```
